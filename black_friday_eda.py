# -*- coding: utf-8 -*-
"""Black Friday EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1koZ_NsqbWm7BGiQNuiVsAqrik-p-ePBC

#**BLACK FRIDAY DATASET EDA AND FEATURE ENGINEERING**
##CLEANING AND PREPARING THE MODEL FOR TRAINING
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#importing the dataset
df_train = pd.read_csv("train.csv")
df_test = pd.read_csv("test.csv")

df_train.head()

df_test.head()

#merging the 2 dataset
df = pd.concat([df_train, df_test])
df.head()

#Basic
df.info()

df.describe()

df.drop(['User_ID'], axis=1, inplace=True)

df.head()

##Encoding Catogorical features
df["Gender"] = df['Gender'].map({'F':0, 'M':1})
df.head()

df['Age'].unique()

df['Age'] = df['Age'].map({'0-17':1,'18-25':2,'26-35':3 , '36-45':4, '46-50':5, '51-55':6, '55+':7})
df.head()

city_df = pd.get_dummies(df['City_Category'], drop_first=True)
city_df.head()

df = pd.concat([df, city_df], axis=1)
df.drop(["City_Category"], axis=1, inplace=True)
df.head()

## Check missing values
df.isnull().sum()

## focus on replacing missing values
df['Product_Category_2'].unique()

df['Product_Category_2'].value_counts()

mode = df['Product_Category_2'].mode()[0]

df['Product_Category_2'] = df['Product_Category_3'].fillna(mode)

df['Product_Category_3'] = df['Product_Category_3'].fillna(df['Product_Category_3'].mode()[0])

df.head(9)

df['Stay_In_Current_City_Years'].unique()

df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].str.replace('+', '')

df.head(10)

df.info()

## convert objects into integers
df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].astype(int)
df.info()

df['B'] = df['B'].astype(int)
df['C'] = df['C'].astype(int)

df.info()

## visualization of Age vs Purchase
sns.barplot(data=df, x='Age',y='Purchase',hue='Gender')

"""Purchase Of Men is Higher than Women"""

## purchase vs occupation
sns.barplot(x='Occupation', y='Purchase', hue='Gender', data=df)

##Purchase vs Product_Category
sns.barplot(data=df, y="Purchase", x="Product_Category_1", hue='Gender')

sns.barplot(data=df, y="Purchase", x="Product_Category_2", hue='Gender')

sns.barplot(data=df, y="Purchase", x="Product_Category_3", hue='Gender')

## Feature Scaling
df_test = df[df['Purchase'].isnull()]

df_train = df[~df['Purchase'].isnull()]
df_train.Product_ID.value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_train['Product_ID'] = le.fit_transform(df_train['Product_ID'])
df_train

X = df_train.drop( 'Purchase', axis=1).values
y = df_train['Purchase'].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from xgboost import XGBRegressor
model = XGBRegressor()
model.fit(X_train, y_train)

## Accuracy on train Data
y_pred = model.predict(X_train)
from sklearn.metrics import r2_score, mean_absolute_error
print(r2_score(y_pred, y_train))
print(mean_absolute_error(y_pred, y_train))

## Accuracy on test Data
y_pred = model.predict(X_test)
from sklearn.metrics import r2_score, mean_absolute_error
print(r2_score(y_pred, y_test))
print(mean_absolute_error(y_pred, y_test))

from sklearn.ensemble import RandomForestRegressor
model_2 = RandomForestRegressor()
model_2.fit(X_train, y_train)

## Accuracy on train Data
y_pred = model_2.predict(X_train)
from sklearn.metrics import r2_score, mean_absolute_error
print(r2_score(y_pred, y_train))
print(mean_absolute_error(y_pred, y_train))

## Accuracy on test Data
y_pred = model_2.predict(X_test)
from sklearn.metrics import r2_score, mean_absolute_error
print(r2_score(y_pred, y_test))
print(mean_absolute_error(y_pred, y_test))